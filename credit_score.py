# Importando as Bibliotecas 
from sklearn import datasets
import streamlit as st # type: ignore
import io
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

import statsmodels.formula.api as smf
import statsmodels.api as sm

import warnings
warnings.filterwarnings("ignore")

from sklearn import metrics
from scipy.stats import ks_2samp
from scipy.stats import t
from statsmodels.stats.outliers_influence import variance_inflation_factor as vif

#######
st.set_page_config(page_title="An√°lise de Cr√©dito", layout="wide")

# Cabe√ßalho com imagem hospedada
st.markdown(
    """
    <div style='text-align: center; padding: 10px;'>
        <img src='https://github.com/Samuel-Oliveira-saturno/Cred_Score_mod38_Projeto_Final/blob/main/logo_banco.jpg' width='150'>
        <h1 style='color: #4CAF50;'>Projeto de An√°lise de Cr√©dito</h1>
        <p style='font-size: 18px;'>Aplica√ß√£o em PyCaret com Streamlit</p>
        <hr style='border: 1px solid #ccc;'>
    </div>
    """,
    unsafe_allow_html=True
)


#######

st.title('üìä An√°lise de Cr√©dito')
# Bot√¢o para carregar o banco de dados
uploaded_file = st.file_uploader("üìÅCarregar banco de Dados (.ftr)", type="ftr")

if uploaded_file is not None:
    df = pd.read_feather(uploaded_file)
    st.success("Arquivo carregado com sucesso!")

    st.subheader("üìåVisualiza√ß√£o dos dados")
    st.dataframe(df)

    # Tratamento de dados 
    st.subheader("üìà Estat√≠sticas")
    st.write(df.describe())

    # Obter o valor m√≠nimo e m√°ximo da coluna 'data_ref'
    st.subheader("üìÖ Intervalo de datas em 'data_ref'")
    min_date = df['data_ref'].min()
    max_date = df['data_ref'].max()
    st.write(f"üîΩ Data m√≠nima: {min_date}")
    st.write(f"üîº Data m√°xima: {max_date}")

     # Retornando os √∫ltimos 3 meses (a partir de 01/01/2016 como exemplo)
    st.subheader("üìÖ √öltimos 3 meses (simulados)")
    meses = 3  # Define a quantidade de meses a serem gerados

    # Cria uma s√©rie de datas, iniciando em '01/01/2016', com 'meses' per√≠odos e frequ√™ncia mensal
    data = pd.Series(pd.date_range('1/1/2016', periods=meses, freq='MS'))

    # Converte a s√©rie em um DataFrame e renomeia a coluna
    date = pd.DataFrame(data)
    date = date.rename({0: 'oot'}, axis='columns')

    # Exibe o DataFrame resultante
    st.dataframe(date)

    st.subheader("üìå Descritiva B√°sica Univariada")

    # N√∫mero de linhas do DataFrame 'df'
    st.write(f"üî¢ N√∫mero de linhas no DataFrame: {df.shape[0]}")

    # Contagem de ocorr√™ncias de cada valor no DataFrame 'date'
    st.write("üìÜ Ocorr√™ncias das datas em 'date':")
    st.dataframe(date.value_counts())

    # Contagem de ocorr√™ncias de cada valor √∫nico na coluna 'data_ref' do DataFrame 'df'
    st.write("üïí Ocorr√™ncias por data em 'data_ref':")
    st.dataframe(df['data_ref'].value_counts())

    st.subheader("‚ÑπÔ∏è Informa√ß√µes do DataFrame (df.info())")

    buffer = io.StringIO()
    df.info(buf=buffer)
    info_str = buffer.getvalue()
    st.text(info_str)


st.subheader("üìâ Distribui√ß√£o da vari√°vel 'mau'")

var = 'mau'

if var in df.columns:
        st.write("Contagem de valores √∫nicos:")
        st.dataframe(df[var].value_counts())

        # Criar gr√°fico de barras
        fig, ax = plt.subplots()
        df[var].value_counts().plot.bar(ax=ax, color='skyblue')
        ax.set_title(f"Distribui√ß√£o da vari√°vel '{var}'")
        ax.set_xlabel(var)
        ax.set_ylabel("Frequ√™ncia")

        # Exibir gr√°fico no Streamlit
        st.pyplot(fig)
else:
        st.warning(f"A coluna '{var}' n√£o foi encontrada no DataFrame.")


st.subheader("üìä Distribui√ß√£o da vari√°vel 'sexo'")

if 'sexo' in df.columns:
        # Contagem dos valores √∫nicos
        st.write("Contagem de valores √∫nicos:")
        st.dataframe(df['sexo'].value_counts())

        # Limpar figuras anteriores
        plt.clf()

        var = "sexo"

        # Criar histograma com seaborn
        fig = sns.displot(df, x=var, bins=50, color='skyblue', edgecolor='black', alpha=0.8)

        plt.title("Distribui√ß√£o da vari√°vel 'sexo'", fontsize=14)

        # Exibir gr√°fico no Streamlit
        st.pyplot(fig)
else:
        st.warning("A coluna 'sexo' n√£o foi encontrada no DataFrame.")


st.subheader("üöó Distribui√ß√£o da vari√°vel 'posse_de_veiculo'")

if 'posse_de_veiculo' in df.columns:
        # Contagem dos valores √∫nicos
        st.write("Contagem de valores √∫nicos:")
        st.dataframe(df['posse_de_veiculo'].value_counts())

        # Limpar figuras anteriores
        plt.clf()

        var = "posse_de_veiculo"

        # Criar histograma com seaborn
        fig = sns.displot(df, x=var, bins=50, color='skyblue', edgecolor='black', alpha=0.8)

        plt.title("Distribui√ß√£o da vari√°vel 'posse_de_veiculo'", fontsize=14)

        # Exibir gr√°fico no Streamlit
        st.pyplot(fig)
else:
        st.warning("A coluna 'posse_de_veiculo' n√£o foi encontrada no DataFrame.")


st.subheader("üè† Distribui√ß√£o da vari√°vel 'posse_de_imovel'")

if 'posse_de_imovel' in df.columns:
        # Contagem dos valores √∫nicos
        st.write("Contagem de valores √∫nicos:")
        st.dataframe(df['posse_de_imovel'].value_counts())

        # Limpar figuras anteriores
        plt.clf()

        var = "posse_de_imovel"

        # Criar histograma com seaborn
        fig = sns.displot(df, x=var, bins=50, color='skyblue', edgecolor='black', alpha=0.8)

        plt.title("Distribui√ß√£o da vari√°vel 'posse_de_imovel'", fontsize=14)

        # Exibir gr√°fico no Streamlit
        st.pyplot(fig)
else:
        st.warning("A coluna 'posse_de_imovel' n√£o foi encontrada no DataFrame.")



st.subheader("üíº Distribui√ß√£o da vari√°vel 'tipo_renda'")

if 'tipo_renda' in df.columns:
        # Contagem dos valores √∫nicos
        st.write("Contagem de valores √∫nicos:")
        st.dataframe(df['tipo_renda'].value_counts())

        # Define o tamanho da figura
        plt.figure(figsize=(10, 5))

        # Gr√°fico de barras com seaborn
        sns.countplot(x=df["tipo_renda"], color='skyblue', edgecolor='black', alpha=0.8)

        # T√≠tulos e r√≥tulos
        plt.title("Distribui√ß√£o da vari√°vel 'tipo_renda'", fontsize=14)
        plt.xlabel("Tipo de Renda", fontsize=12)
        plt.ylabel("Contagem", fontsize=12)
        plt.xticks(rotation=90)

        # Exibir no Streamlit
        st.pyplot(plt.gcf())  # gcf = get current figure
else:
        st.warning("A coluna 'tipo_renda' n√£o foi encontrada no DataFrame.")


st.subheader("üéì Distribui√ß√£o da vari√°vel 'educacao'")

if 'educacao' in df.columns:
        # Contagem dos valores √∫nicos
        st.write("Contagem de valores √∫nicos:")
        st.dataframe(df['educacao'].value_counts())

        # Define o tamanho da figura
        plt.figure(figsize=(10, 5))

        # Gr√°fico de barras com seaborn
        sns.countplot(x=df["educacao"], color='skyblue', edgecolor='black', alpha=0.8)

        # T√≠tulos e r√≥tulos
        plt.title("Distribui√ß√£o da vari√°vel 'educacao'", fontsize=14)
        plt.xlabel("Educa√ß√£o", fontsize=12)
        plt.ylabel("Contagem", fontsize=12)
        plt.xticks(rotation=90)

        # Exibir no Streamlit
        st.pyplot(plt.gcf())
else:
        st.warning("A coluna 'educacao' n√£o foi encontrada no DataFrame.")


st.subheader("üíç Distribui√ß√£o da vari√°vel 'estado_civil'")

if 'estado_civil' in df.columns:
        # Contagem dos valores √∫nicos
        st.write("Contagem de valores √∫nicos:")
        st.dataframe(df['estado_civil'].value_counts())

        # Define o tamanho da figura
        plt.figure(figsize=(10, 5))

        # Gr√°fico de barras com seaborn
        sns.countplot(x=df["estado_civil"], color='skyblue', edgecolor='black', alpha=0.8)

        # T√≠tulos e r√≥tulos
        plt.title("Distribui√ß√£o da vari√°vel 'estado_civil'", fontsize=14)
        plt.xlabel("Estado Civil", fontsize=12)
        plt.ylabel("Contagem", fontsize=12)
        plt.xticks(rotation=90)

        # Exibir no Streamlit
        st.pyplot(plt.gcf())
else:
        st.warning("A coluna 'estado_civil' n√£o foi encontrada no DataFrame.")



st.subheader("üè† Distribui√ß√£o da vari√°vel 'tipo_residencia'")

if 'tipo_residencia' in df.columns:
        # Contagem dos valores √∫nicos
        st.write("Contagem de valores √∫nicos:")
        st.dataframe(df['tipo_residencia'].value_counts())

        # Define o tamanho da figura
        plt.figure(figsize=(10, 5))

        # Gr√°fico de barras com seaborn
        sns.countplot(x=df["tipo_residencia"], color='skyblue', edgecolor='black', alpha=0.8)

        # T√≠tulos e r√≥tulos
        plt.title("Distribui√ß√£o da vari√°vel 'tipo_residencia'", fontsize=14)
        plt.xlabel("Tipo de Resid√™ncia", fontsize=12)
        plt.ylabel("Contagem", fontsize=12)
        plt.xticks(rotation=90)

        # Exibir no Streamlit
        st.pyplot(plt.gcf())
else:
        st.warning("A coluna 'tipo_residencia' n√£o foi encontrada no DataFrame.")


st.subheader("üë∂ Distribui√ß√£o da vari√°vel 'qtd_filhos'")

if 'qtd_filhos' in df.columns:
        # Contagem dos valores √∫nicos
        st.write("Contagem de valores √∫nicos:")
        st.dataframe(df['qtd_filhos'].value_counts())

        # Define o tamanho da figura
        plt.figure(figsize=(10, 5))

        # Gr√°fico de barras com seaborn
        sns.countplot(x=df["qtd_filhos"], color='skyblue', edgecolor='black', alpha=0.8)

        # T√≠tulos e r√≥tulos
        plt.title("Distribui√ß√£o da vari√°vel 'qtd_filhos'", fontsize=14)
        plt.xlabel("Quantidade de Filhos", fontsize=12)
        plt.ylabel("Contagem", fontsize=12)
        plt.xticks(rotation=90)

        # Exibir no Streamlit
        st.pyplot(plt.gcf())
else:
        st.warning("A coluna 'qtd_filhos' n√£o foi encontrada no DataFrame.")



st.subheader("üìä Distribui√ß√£o da vari√°vel 'idade'")

if 'idade' in df.columns:
        # Contagem de valores √∫nicos
        st.write("Contagem de valores √∫nicos:")
        st.dataframe(df['idade'].value_counts().sort_index())

        # Define o tamanho da figura
        plt.figure(figsize=(10, 5))

        # Gr√°fico de barras com Seaborn
        sns.countplot(x=df["idade"], color='skyblue', edgecolor='black', alpha=0.8)

        # T√≠tulos e r√≥tulos
        plt.title("Distribui√ß√£o da vari√°vel 'idade'", fontsize=14)
        plt.xlabel("Idade", fontsize=12)
        plt.ylabel("Contagem", fontsize=12)
        plt.xticks(rotation=90)

        # Exibe no Streamlit
        st.pyplot(plt.gcf())
else:
        st.warning("A coluna 'idade' n√£o foi encontrada no DataFrame.")


st.subheader("üïí Distribui√ß√£o da vari√°vel 'tempo_emprego'")

if 'tempo_emprego' in df.columns:
        # Contagem de valores √∫nicos
        st.write("Contagem de valores √∫nicos:")
        st.dataframe(df['tempo_emprego'].value_counts().sort_index())

        # Limpa figura para evitar sobreposi√ß√£o
        plt.clf()

        # Define vari√°vel de interesse
        var = "tempo_emprego"

        # Cria histograma com Seaborn
        sns.displot(df, x=var, bins=50, color='skyblue', edgecolor='black', alpha=0.8)

        # Exibe gr√°fico
        st.pyplot(plt.gcf())
else:
        st.warning("A coluna 'tempo_emprego' n√£o foi encontrada no DataFrame.")


st.subheader("üè† Distribui√ß√£o da vari√°vel 'qt_pessoas_residencia'")

if 'qt_pessoas_residencia' in df.columns:
        # Contagem de valores √∫nicos
        st.write("Contagem de valores √∫nicos:")
        st.dataframe(df['qt_pessoas_residencia'].value_counts().sort_index())

        # Limpa figura para evitar sobreposi√ß√£o
        plt.clf()

        # Define vari√°vel
        var = "qt_pessoas_residencia"

        # Cria histograma com Seaborn
        sns.displot(df, x=var, bins=50, color='skyblue', edgecolor='black', alpha=0.8)

        # Exibe gr√°fico
        st.pyplot(plt.gcf())
else:
        st.warning("A coluna 'qt_pessoas_residencia' n√£o foi encontrada no DataFrame.")


st.subheader("üí∞ Distribui√ß√£o da vari√°vel 'renda'")

if 'renda' in df.columns:
        # Contagem de valores √∫nicos (opcional)
        st.write("Estat√≠sticas descritivas da vari√°vel 'renda':")
        st.dataframe(df['renda'].describe())

        # Limpa figura para evitar sobreposi√ß√£o
        plt.clf()

        # Define vari√°vel
        var = "renda"

        # Cria histograma com Seaborn
        sns.displot(df, x=var, bins=50, color='skyblue', edgecolor='black', alpha=0.8)

        # Exibe gr√°fico
        st.pyplot(plt.gcf())
else:
        st.warning("A coluna 'renda' n√£o foi encontrada no DataFrame.")


st.subheader("‚úÖ An√°lise Bivariada: Vari√°vel categ√≥rica vs 'mau'")

    # Seleciona vari√°veis categ√≥ricas automaticamente (excluindo a 'mau')
variaveis_categoricas = df.select_dtypes(include='object').columns.tolist()

    # Adiciona manualmente outras que sejam categ√≥ricas mas n√£o de tipo 'object'
outras_categoricas = ['sexo', 'posse_de_imovel', 'posse_de_veiculo', 'tipo_renda', 
                          'educacao', 'estado_civil', 'tipo_residencia', 'qtd_filhos']

for var in outras_categoricas:
        if var not in variaveis_categoricas and var in df.columns:
            variaveis_categoricas.append(var)

    # Interface interativa para escolher vari√°vel categ√≥rica
var_categorica = st.selectbox("Selecione uma vari√°vel categ√≥rica:", variaveis_categoricas)

if var_categorica in df.columns and 'mau' in df.columns:
        plt.clf()
        sns.barplot(x=var_categorica, y='mau', data=df, ci=None, palette='pastel', edgecolor='black')

        # Personaliza o gr√°fico
        plt.title(f"M√©dia de 'mau' por categoria de '{var_categorica}'", fontsize=14)
        plt.xlabel(var_categorica, fontsize=12)
        plt.ylabel("M√©dia de 'mau'", fontsize=12)
        plt.xticks(rotation=45)

        # Exibe gr√°fico
        st.pyplot(plt.gcf())
else:
        st.warning("Coluna 'mau' ou vari√°vel categ√≥rica n√£o encontrada.")


st.subheader("An√°lise bivariada: posse de ve√≠culo vs inadimpl√™ncia")

# Limpa a figura anterior (caso esteja em loop ou repeti√ß√£o)
plt.clf()

# Gr√°fico de barras da m√©dia de 'mau' para cada valor de 'posse_de_veiculo'
sns.barplot(x='posse_de_veiculo', y='mau', data=df, ci=None, palette='pastel', edgecolor='black')

# Personaliza√ß√£o do gr√°fico
plt.title("Inadimpl√™ncia m√©dia por posse de ve√≠culo", fontsize=14)
plt.xlabel("Possui ve√≠culo", fontsize=12)
plt.ylabel("M√©dia de inadimpl√™ncia (mau)", fontsize=12)

# Exibe o gr√°fico
st.pyplot(plt.gcf())


st.subheader("An√°lise bivariada: posse de im√≥vel vs inadimpl√™ncia")

if 'posse_de_imovel' in df.columns and 'mau' in df.columns:
        # Limpa a figura anterior
        plt.clf()

        # Cria o gr√°fico de barras
        sns.barplot(x='posse_de_imovel', y='mau', data=df, ci=None, palette='pastel', edgecolor='black')

        # Personaliza
        plt.title("Inadimpl√™ncia m√©dia por posse de im√≥vel", fontsize=14)
        plt.xlabel("Possui im√≥vel", fontsize=12)
        plt.ylabel("M√©dia de inadimpl√™ncia (mau)", fontsize=12)

        # Exibe no Streamlit
        st.pyplot(plt.gcf())
else:
        st.warning("Colunas 'posse_de_imovel' ou 'mau' n√£o encontradas no DataFrame.")


st.subheader("üíº An√°lise bivariada: tipo de renda vs inadimpl√™ncia")

if 'tipo_renda' in df.columns and 'mau' in df.columns:
        # Limpa figuras anteriores
        plt.clf()

        # Cria o gr√°fico de barras
        tipo_renda = sns.barplot(x='tipo_renda', y='mau', data=df, ci=None, palette='pastel', edgecolor='black')

        # Personaliza√ß√£o do eixo X
        tipo_renda.set_xticklabels(tipo_renda.get_xticklabels(), rotation=45, horizontalalignment='right')

        # T√≠tulos
        plt.title("Inadimpl√™ncia m√©dia por tipo de renda", fontsize=14)
        plt.xlabel("Tipo de Renda", fontsize=12)
        plt.ylabel("M√©dia de Inadimpl√™ncia (mau)", fontsize=12)

        # Exibe no Streamlit
        st.pyplot(plt.gcf())
else:
        st.warning("Colunas 'tipo_renda' ou 'mau' n√£o encontradas no DataFrame.")


st.subheader("üéì An√°lise bivariada: educa√ß√£o vs inadimpl√™ncia")

if 'educacao' in df.columns and 'mau' in df.columns:
        # Limpa figuras anteriores
        plt.clf()

        # Cria o gr√°fico de barras
        educacao = sns.barplot(x='educacao', y='mau', data=df, ci=None, palette='pastel', edgecolor='black')

        # Ajusta os r√≥tulos do eixo X
        educacao.set_xticklabels(educacao.get_xticklabels(), rotation=45, horizontalalignment='right')

        # T√≠tulos
        plt.title("Inadimpl√™ncia m√©dia por n√≠vel de educa√ß√£o", fontsize=14)
        plt.xlabel("Educa√ß√£o", fontsize=12)
        plt.ylabel("M√©dia de inadimpl√™ncia (mau)", fontsize=12)

        # Exibe no Streamlit
        st.pyplot(plt.gcf())
else:
        st.warning("Colunas 'educacao' ou 'mau' n√£o encontradas no DataFrame.")


st.subheader("üíç An√°lise bivariada: estado civil vs inadimpl√™ncia")

if 'estado_civil' in df.columns and 'mau' in df.columns:
        # Limpa figuras anteriores
        plt.clf()

        # Cria o gr√°fico de barras
        estado_civil = sns.barplot(x='estado_civil', y='mau', data=df, ci=None, palette='pastel', edgecolor='black')

        # Ajusta os r√≥tulos do eixo X
        estado_civil.set_xticklabels(estado_civil.get_xticklabels(), rotation=45, horizontalalignment='right')

        # T√≠tulos
        plt.title("Inadimpl√™ncia m√©dia por estado civil", fontsize=14)
        plt.xlabel("Estado Civil", fontsize=12)
        plt.ylabel("M√©dia de inadimpl√™ncia (mau)", fontsize=12)

        # Exibe no Streamlit
        st.pyplot(plt.gcf())
else:
        st.warning("Colunas 'estado_civil' ou 'mau' n√£o encontradas no DataFrame.")


st.subheader("üè† An√°lise bivariada: tipo de resid√™ncia vs inadimpl√™ncia")

if 'tipo_residencia' in df.columns and 'mau' in df.columns:
        # Limpa figuras anteriores
        plt.clf()

        # Cria o gr√°fico de barras
        tipo_residencia = sns.barplot(x='tipo_residencia', y='mau', data=df, ci=None, palette='pastel', edgecolor='black')

        # Ajusta os r√≥tulos do eixo X
        tipo_residencia.set_xticklabels(tipo_residencia.get_xticklabels(), rotation=90, horizontalalignment='right')

        # T√≠tulos
        plt.title("Inadimpl√™ncia m√©dia por tipo de resid√™ncia", fontsize=14)
        plt.xlabel("Tipo de Resid√™ncia", fontsize=12)
        plt.ylabel("M√©dia de inadimpl√™ncia (mau)", fontsize=12)

        # Exibe no Streamlit
        st.pyplot(plt.gcf())
else:
        st.warning("Colunas 'tipo_residencia' ou 'mau' n√£o encontradas no DataFrame.")


st.subheader("üßº Verifica√ß√£o de valores ausentes (missing values)")

missing_values = df.isna().sum()
st.dataframe(missing_values[missing_values > 0].sort_values(ascending=False))

if missing_values.sum() == 0:
        st.success("‚úÖ Nenhum valor ausente encontrado no DataFrame!")


st.subheader("üìå Tratamento de valores ausentes na coluna 'tempo_emprego'")

if 'tempo_emprego' in df.columns:
        # Antes do preenchimento
        missing_before = df['tempo_emprego'].isna().sum()
        st.write(f"Valores ausentes antes do preenchimento: {missing_before}")

        # Preenchimento com a m√©dia
        df['tempo_emprego'] = df['tempo_emprego'].fillna(df['tempo_emprego'].mean())

        # Ap√≥s o preenchimento
        missing_after = df['tempo_emprego'].isna().sum()
        st.write(f"Valores ausentes ap√≥s o preenchimento: {missing_after}")
else:
        st.warning("Coluna 'tempo_emprego' n√£o encontrada no DataFrame.")


st.subheader("üìä Metadados do DataFrame")

    # Cria o DataFrame com tipo de dado
metadados = pd.DataFrame(df.dtypes, columns=['dtype'])

    # Adiciona a quantidade de valores √∫nicos por coluna
metadados['valores_unicos'] = df.nunique()

    # Exibe a tabela no Streamlit
st.dataframe(metadados)


st.subheader("üîÑ Convers√£o da vari√°vel 'mau' para tipo inteiro")

if 'mau' in df.columns:
        df['mau'] = df['mau'].astype('int64')
        st.success("Coluna 'mau' convertida com sucesso para int64!")
        st.write(df['mau'].dtypes)
else:
        st.warning("A coluna 'mau' n√£o foi encontrada no DataFrame.")



st.subheader("üìà C√°lculo do IV (Information Value)")

    # Define a fun√ß√£o IV
def IV(variavel, resposta):
        tab = pd.crosstab(variavel, resposta, margins=True, margins_name='total')
        r√≥tulo_evento = tab.columns[0]
        r√≥tulo_nao_evento = tab.columns[1]

        tab['pct_evento'] = tab[r√≥tulo_evento] / tab.loc['total', r√≥tulo_evento]
        tab['pct_nao_evento'] = tab[r√≥tulo_nao_evento] / tab.loc['total', r√≥tulo_nao_evento]
        tab['woe'] = np.log(tab.pct_evento / tab.pct_nao_evento)
        tab['iv_parcial'] = (tab.pct_evento - tab.pct_nao_evento) * tab.woe

        return tab['iv_parcial'].sum()

    # Seleciona vari√°veis categ√≥ricas para an√°lise de IV
variaveis_categoricas = df.select_dtypes(include='object').columns.tolist()
extras = ['sexo', 'posse_de_imovel', 'posse_de_veiculo', 'tipo_renda', 
              'educacao', 'estado_civil', 'tipo_residencia']

for col in extras:
        if col not in variaveis_categoricas and col in df.columns:
            variaveis_categoricas.append(col)

    # Interface para escolha da vari√°vel
var_iv = st.selectbox("Selecione a vari√°vel para calcular o IV:", variaveis_categoricas)

if var_iv and 'mau' in df.columns:
        iv_valor = IV(df[var_iv], df['mau'])
        st.write(f"üìä IV para a vari√°vel **{var_iv}**: `{iv_valor:.4f}`")

        # Interpreta√ß√£o (opcional)
        if iv_valor < 0.02:
            interpret = "Vari√°vel n√£o preditiva"
        elif iv_valor < 0.1:
            interpret = "Poder preditivo fraco"
        elif iv_valor < 0.3:
            interpret = "Poder preditivo m√©dio"
        elif iv_valor < 0.5:
            interpret = "Boa vari√°vel preditiva"
        else:
            interpret = "Forte poder preditivo"

        st.info(f"üß† Interpreta√ß√£o: **{interpret}**")
else:
        st.warning("Selecione uma vari√°vel v√°lida e certifique-se de que 'mau' est√° no DataFrame.")


st.subheader("üìå IV da vari√°vel 'sexo'")

if 'sexo' in df.columns and 'mau' in df.columns:
        iv_sexo = IV(df['sexo'], df['mau'])
        st.success(f"IV da vari√°vel **SEXO**: `{iv_sexo:.1%}`")
else:
        st.warning("Colunas 'sexo' ou 'mau' n√£o encontradas no DataFrame.")


st.subheader("üìë Constru√ß√£o de metadados para modelagem")

    # Cria o DataFrame com tipos e valores √∫nicos
metadados = pd.DataFrame(df.dtypes, columns=['dtype'])
metadados['valores_unicos'] = df.nunique()
metadados['variavel'] = 'covariavel'  # define tudo inicialmente como covari√°vel

    # Define 'mau' como vari√°vel resposta (se existir)
if 'mau' in df.columns:
        metadados.loc['mau', 'variavel'] = 'resposta'

    # Verifica se 'bom' existe antes de definir como resposta
if 'bom' in df.columns:
        metadados.loc['bom', 'variavel'] = 'resposta'

    # Exibe o resultado
st.dataframe(metadados)


st.subheader("üìä IV da vari√°vel num√©rica 'idade' (quintis)")

var = 'idade'

if var in df.columns and 'mau' in df.columns:
        try:
            # Divide 'idade' em 5 grupos com base nos quantis
            idade_quantis = pd.qcut(df[var], 5, duplicates='drop')

            # Calcula o IV usando a fun√ß√£o definida anteriormente
            iv_idade = IV(idade_quantis, df['mau'])

            st.success(f"IV da vari√°vel 'idade' (dividida em quintis): `{iv_idade:.4f}`")
        except Exception as e:
            st.error(f"Erro ao calcular IV para 'idade': {e}")
else:
        st.warning("As colunas 'idade' ou 'mau' n√£o foram encontradas no DataFrame.")



st.subheader("üß† C√°lculo do Information Value (IV) para todas as covari√°veis")

    # Garante que o campo 'IV' existe
metadados['IV'] = np.nan

    # Loop pelas vari√°veis definidas como 'covariavel'
for var in metadados[metadados['variavel'] == 'covariavel'].index:
        try:
            if metadados.loc[var, 'valores_unicos'] > 6:
                # Trata como vari√°vel cont√≠nua (binning em quintis)
                metadados.loc[var, 'IV'] = IV(pd.qcut(df[var], 5, duplicates='drop'), df['mau'])
            else:
                # Trata como categ√≥rica
                metadados.loc[var, 'IV'] = IV(df[var], df['mau'])
        except Exception as e:
            st.warning(f"‚ö†Ô∏è Erro ao calcular IV para '{var}': {e}")

    # Exibe os resultados ordenados pelo IV
metadados_iv = metadados.dropna(subset=['IV']).sort_values('IV', ascending=False)
st.dataframe(metadados_iv)





def biv_discreta(var, df):
        df = df.copy()

        # Cria a vari√°vel 'bom' como complemento de 'mau'
        df['bom'] = 1 - df['mau']

        # Agrupa os dados
        g = df.groupby(var)
        biv = pd.DataFrame({
            'qt_bom': g['bom'].sum(),
            'qt_mau': g['mau'].sum(),
            'mau': g['mau'].mean(),
            'cont': g[var].count()
        })

        # Erro padr√£o da m√©dia de 'mau'
        biv['ep'] = np.sqrt(biv['mau'] * (1 - biv['mau']) / biv['cont'])

        # Intervalos de confian√ßa (95%)
        biv['mau_sup'] = biv['mau'] + t.ppf(0.975, biv['cont'] - 1) * biv['ep']
        biv['mau_inf'] = biv['mau'] + t.ppf(0.025, biv['cont'] - 1) * biv['ep']

        # Logits
        biv['logit'] = np.log(biv['mau'] / (1 - biv['mau']))
        biv['logit_sup'] = np.log(biv['mau_sup'] / (1 - biv['mau_sup']))
        biv['logit_inf'] = np.log(biv['mau_inf'] / (1 - biv['mau_inf']))

        # WOE
        woe_geral = np.log(df['mau'].mean() / (1 - df['mau'].mean()))
        biv['woe'] = biv['logit'] - woe_geral
        biv['woe_sup'] = biv['logit_sup'] - woe_geral
        biv['woe_inf'] = biv['logit_inf'] - woe_geral

        # Gr√°ficos
        fig, ax = plt.subplots(2, 1, figsize=(8, 6))
        x_labels = biv.index.astype(str)

        # Gr√°fico WOE
        ax[0].plot(x_labels, biv['woe'], 'o-b', label='WOE')
        ax[0].plot(x_labels, biv['woe_sup'], 'o:r', label='Limite Superior')
        ax[0].plot(x_labels, biv['woe_inf'], 'o:r', label='Limite Inferior')
        ax[0].set_ylabel("Weight of Evidence")
        ax[0].legend(bbox_to_anchor=(1.05, 1), loc='upper left')
        ax[0].set_xticks(range(len(x_labels)))
        ax[0].set_xticklabels(x_labels, rotation=15)

        # Gr√°fico de contagem
        biv['cont'].plot(kind='bar', ax=ax[1], color='lightblue', edgecolor='black')
        ax[1].set_ylabel("Contagem")
        ax[1].set_xlabel(var)
        ax[1].set_xticks(range(len(x_labels)))
        ax[1].set_xticklabels(x_labels, rotation=15)

        plt.tight_layout()
        st.pyplot(fig)

        return biv


st.subheader("üíç An√°lise Bivariada: estado_civil vs mau")

if 'estado_civil' in df.columns and 'mau' in df.columns:
        resultado_woe = biv_discreta('estado_civil', df)
        st.dataframe(resultado_woe)
else:
        st.warning("A coluna 'estado_civil' ou 'mau' n√£o foi encontrada.")


st.subheader("üß™ An√°lise Bivariada com Agrupamento: tipo_renda vs mau")

if 'tipo_renda' in df.columns:
        # Cria uma c√≥pia para preservar o DataFrame original
        df2 = df.copy()

        # Agrupamento de categorias
        df2['tipo_renda'] = df2['tipo_renda'].replace({
            'Bolsista': 'Bols./SerPubl',
            'Servidor p√∫blico': 'Bols./SerPubl'
        })

        # Aplica a an√°lise bivariada com WOE
        resultado_tipo_renda = biv_discreta('tipo_renda', df2)
        st.dataframe(resultado_tipo_renda)
else:
        st.warning("A coluna 'tipo_renda' n√£o foi encontrada.")



st.subheader("üìà IV da vari√°vel 'tipo_renda' ap√≥s agrupamento")

if 'tipo_renda' in df.columns and 'mau' in df.columns:
        # Cria c√≥pia modificada com categorias agrupadas
        df2 = df.copy()
        df2['tipo_renda'] = df2['tipo_renda'].replace({
            'Bolsista': 'Bols./SerPubl',
            'Servidor p√∫blico': 'Bols./SerPubl'
        })

        # Calcula o IV da nova vers√£o da vari√°vel
        iv_tipo_renda_agrupada = IV(df2['tipo_renda'], df['mau'])

        st.success(f"IV de 'tipo_renda' ap√≥s agrupamento: `{iv_tipo_renda_agrupada:.4f}`")
else:
        st.warning("Colunas 'tipo_renda' ou 'mau' n√£o encontradas.")


st.subheader("üéì An√°lise Bivariada com Agrupamento: educacao vs mau")

if 'educacao' in df.columns:
        # C√≥pia do DataFrame para n√£o alterar o original
        df2 = df.copy()

        # Agrupamento das categorias de escolaridade
        df2['educacao'] = df2['educacao'].replace({
            'Superior completo': 'Sup.Compl/PosGra',
            'P√≥s gradua√ß√£o': 'Sup.Compl/PosGra'
        })

        # Aplica an√°lise bivariada com WOE
        resultado_educacao = biv_discreta('educacao', df2)
        st.dataframe(resultado_educacao)
else:
        st.warning("A coluna 'educacao' n√£o foi encontrada.")


iv_educacao_agrupada = IV(df2['educacao'], df['mau'])
st.success(f"IV de 'educacao' ap√≥s agrupamento: `{iv_educacao_agrupada:.4f}`")


st.subheader("üéì An√°lise Bivariada com Agrupamento Refinado: educacao vs mau")

if 'educacao' in df.columns:
        # C√≥pia do DataFrame
        df2 = df.copy()

        # Primeiro agrupamento anterior
        df2['educacao'] = df2['educacao'].replace({
            'Superior completo': 'Sup.Compl/PosGra',
            'P√≥s gradua√ß√£o': 'Sup.Compl/PosGra'
        })

        # Agrupamento refinado adicional
        df2['educacao'] = df2['educacao'].replace({
            'Superior incompleto': 'Sup.Compl/PosGra',
            'Fundamental': 'Funda./M√©d',
            'M√©dio': 'Funda./M√©d'
        })

        # Aplica an√°lise bivariada
        resultado_educacao = biv_discreta('educacao', df2)
        st.dataframe(resultado_educacao)

        # Calcula o novo IV ap√≥s o agrupamento
        iv_educacao_agrupada = IV(df2['educacao'], df['mau'])
        st.success(f"IV de 'educacao' ap√≥s agrupamento completo: `{iv_educacao_agrupada:.4f}`")
else:
        st.warning("A coluna 'educacao' n√£o foi encontrada.")


st.subheader("üìÖ Crosstab entre 'mau' e base out-of-time (oot)")

try:
        crosstab = pd.crosstab(df['mau'], date['oot'])
        st.dataframe(crosstab)
except Exception as e:
        st.error(f"Erro ao gerar crosstab: {e}")


st.subheader("üîç Verifica√ß√£o de valores ausentes por coluna")
st.dataframe(df.isna().sum()[df.isna().sum() > 0])


#teste

from sklearn.compose import ColumnTransformer
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split

# Identifica colunas num√©ricas e categ√≥ricas
num_cols = df.select_dtypes(include=['float64', 'int64']).drop(columns=['mau']).columns.tolist()
cat_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()

# Pipelines individuais
num_pipeline = Pipeline([
    ('imputer', SimpleImputer(strategy='mean')),
    ('scaler', StandardScaler())
])

cat_pipeline = Pipeline([
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('encoder', OneHotEncoder(drop='first', handle_unknown='ignore'))
])

# Une os pipelines com ColumnTransformer
preprocessor = ColumnTransformer([
    ('num', num_pipeline, num_cols),
    ('cat', cat_pipeline, cat_cols)
])

# Pipeline completo com modelo
model_pipeline = Pipeline([
    ('preprocessing', preprocessor),
    ('classifier', LogisticRegression(max_iter=200))
])


# Supondo que a vari√°vel alvo √© 'mau'
X = df.drop(columns=['mau'])
y = df['mau']

# Divis√£o treino/teste
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Treinamento
model_pipeline.fit(X_train, y_train)


from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve

# Predi√ß√µes e probabilidades
y_pred = model_pipeline.predict(X_test)
y_proba = model_pipeline.predict_proba(X_test)[:, 1]

# Acur√°cia
acc = accuracy_score(y_test, y_pred)

# AUC (√°rea sob a curva ROC)
auc = roc_auc_score(y_test, y_proba)

# Gini = 2*AUC - 1
gini = 2 * auc - 1

# KS
fpr, tpr, thresholds = roc_curve(y_test, y_proba)
ks = max(tpr - fpr)

print(f"Acur√°cia: {acc:.3f}")
print(f"AUC: {auc:.3f}")
print(f"Gini: {gini:.3f}")
print(f"KS: {ks:.3f}")

#st.subheader("üìã Primeiras linhas do conjunto de dados (X_digits)")

#st.dataframe(X_digits.head())

from sklearn.datasets import load_digits

# Carrega os dados de exemplo
X_digits, y_digits = load_digits(return_X_y=True, as_frame=True)


st.subheader("Primeiras linhas do conjunto de dados (X_digits)")
st.dataframe(X_digits.head())

st.subheader("üìã Primeiras linhas do DataFrame (df2) com pr√©-processamento")

st.dataframe(df2.head())



#####
# app.py

import streamlit as st
import pandas as pd
import numpy as np
from sklearn.datasets import load_digits
from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve
import matplotlib.pyplot as plt

# T√≠tulo do app
st.title("üî¢ PCA + Regress√£o Log√≠stica com Digits")

# Carrega os dados
X_digits, y_digits = load_digits(return_X_y=True, as_frame=True)
st.write("Formato do conjunto de dados:", X_digits.shape)

# Divis√£o treino/teste
X_train, X_test, y_train, y_test = train_test_split(
    X_digits, y_digits, test_size=0.3, random_state=10
)

# Sidebar para configurar n√∫mero de componentes principais
n_components = st.sidebar.slider("Componentes do PCA", 2, X_train.shape[1], 20)

# Pipeline com scaler, PCA e regress√£o log√≠stica
pipeline = Pipeline([
    ('scaler', StandardScaler()),
    ('pca', PCA(n_components=n_components)),
    ('logreg', LogisticRegression(max_iter=200))
])

# Treinamento do modelo
pipeline.fit(X_train, y_train)

# Previs√µes
y_pred = pipeline.predict(X_test)
y_proba = pipeline.predict_proba(X_test)[:, 1]

# M√©tricas
acc = accuracy_score(y_test, y_pred)
auc = roc_auc_score((y_test == y_test.max()).astype(int), y_proba)  # binariza√ß√£o simples para ROC
gini = 2 * auc - 1
fpr, tpr, _ = roc_curve((y_test == y_test.max()).astype(int), y_proba)
ks = max(tpr - fpr)

# Exibe resultados
st.subheader("üìä Resultados")
st.write(f"**Acur√°cia:** {acc:.2%}")
st.write(f"**Gini:** {gini:.4f}")
st.write(f"**KS:** {ks:.4f}")

# Curva ROC
st.subheader("üìâ Curva ROC")
fig, ax = plt.subplots()
ax.plot(fpr, tpr, label='ROC Curve')
ax.plot([0, 1], [0, 1], 'k--', label='Aleat√≥rio')
ax.set_xlabel("FPR")
ax.set_ylabel("TPR")
ax.set_title("Curva ROC")
ax.legend()
st.pyplot(fig)

#####

#####
# Importa o StandardScaler
from sklearn.preprocessing import StandardScaler

# T√≠tulo da se√ß√£o
st.subheader("‚öôÔ∏è Padroniza√ß√£o dos dados (Z-score)")

# Cria uma inst√¢ncia do StandardScaler
scaler = StandardScaler()

# Fit no X_train
scaler.fit(X_train)

# Transforma X_train e X_test
X_train_scaled = scaler.transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Exibe os dados transformados
st.write("üìâ Primeiras linhas do X_train com Z-score aplicado:")
st.dataframe(pd.DataFrame(X_train_scaled).head())

#####

# Importa o PCA
from sklearn.decomposition import PCA

# T√≠tulo da se√ß√£o
st.subheader("üîª Aplicando PCA (Redu√ß√£o de Dimensionalidade)")

# Slider para escolher o n√∫mero de componentes
n_components = st.slider("N√∫mero de componentes principais", 2, X_train_scaled.shape[1], 20)

# Instancia o PCA com o n√∫mero de componentes definido
pca = PCA(n_components=n_components)

# Ajusta (fit) o PCA nos dados padronizados
pca.fit(X_train_scaled)

# Transforma os dados de treino
X_train_pca = pca.transform(X_train_scaled)

# Transforma os dados de teste tamb√©m (com base no PCA do treino)
X_test_pca = pca.transform(X_test_scaled)

# Mostra a vari√¢ncia explicada acumulada
st.write("üìà Vari√¢ncia explicada acumulada:")
st.line_chart(np.cumsum(pca.explained_variance_ratio_))

# Mostra os dados reduzidos
st.write("üîç Primeiras linhas ap√≥s PCA:")
st.dataframe(pd.DataFrame(X_train_pca).head())

#######

# Importa a Regress√£o Log√≠stica
from sklearn.linear_model import LogisticRegression

# T√≠tulo da se√ß√£o
st.subheader("ü§ñ Treinando o Modelo: Regress√£o Log√≠stica")

# Instancia o modelo
logistic = LogisticRegression(max_iter=200)

# Treina o modelo com os dados j√° reduzidos pelo PCA
logistic.fit(X_train_pca, y_train)

# Faz as previs√µes no conjunto de treino
y_train_pred = logistic.predict(X_train_pca)

# Exibe as primeiras previs√µes
st.write("üìã Primeiras previs√µes (treino):")
st.write(y_train_pred[:10])

######

st.subheader("üß™ Previs√µes no conjunto de teste")

# Aplica Z-score no teste com base no treino
X_test_scaled = scaler.transform(X_test)

# Aplica PCA no teste com base no treino
X_test_pca = pca.transform(X_test_scaled)

# Faz previs√µes no conjunto de teste
y_test_pred = logistic.predict(X_test_pca)
y_test_proba = logistic.predict_proba(X_test_pca)[:, 1]

# Exibe as primeiras previs√µes
st.write("üìã Previs√µes (primeiras 10):", y_test_pred[:10])


#######

# Importa√ß√µes necess√°rias
from sklearn.pipeline import Pipeline
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.linear_model import LogisticRegression

st.subheader("üîó Pipeline completo: Z-score + PCA + Regress√£o Log√≠stica")

# Divide os dados
X_train, X_test, y_train, y_test = train_test_split(
    X_digits, y_digits, test_size=0.3, random_state=10
)

# Define os componentes do pipeline
scaler_pipe = StandardScaler()
pca_pipe = PCA(n_components=15)
logistic_pipe = LogisticRegression(max_iter=200)

# Monta o pipeline
pipeline = Pipeline([
    ('scaler', scaler_pipe),
    ('pca', pca_pipe),
    ('logreg', logistic_pipe)
])

# Treina o pipeline
pipeline.fit(X_train, y_train)

# Previs√µes no teste
y_test_pred = pipeline.predict(X_test)
y_test_proba = pipeline.predict_proba(X_test)[:, 1]

# Exibe as primeiras previs√µes
st.write("üìã Previs√µes do pipeline (primeiras 10):", y_test_pred[:10])


#####

st.subheader("‚öôÔ∏è Montando pipeline final: pr√©-processamento + modelo")

# Define o pipeline com os passos nomeados
pipe = Pipeline(steps=[
    ("scaler", scaler_pipe),     # Padroniza√ß√£o (Z-score)
    ("pca", pca_pipe),           # Redu√ß√£o de dimensionalidade
    ("logistic", logistic_pipe)  # Modelo de regress√£o
])

# Treina o pipeline com os dados de treino
pipe.fit(X_train, y_train)

# Faz previs√µes no teste
y_test_pred = pipe.predict(X_test)
y_test_proba = pipe.predict_proba(X_test)[:, 1]

# Exibe primeiras previs√µes
st.write("üìã Previs√µes do pipeline (primeiras 10):")
st.write(y_test_pred[:10])

#########

st.subheader("üîç Etapas do Pipeline")

# Exibe os nomes e objetos das etapas do pipeline
st.write("üì¶ Componentes do pipeline:")
for nome, etapa in pipe.named_steps.items():
    st.markdown(f"**{nome}**: `{etapa}`")

######
st.subheader("üèãÔ∏è‚Äç‚ôÇÔ∏è Treinamento do Pipeline")

# Treinando o pipeline
pipe.fit(X_train, y_train)

st.success("‚úÖ Pipeline treinado com sucesso nos dados de treino!")


st.subheader("üß† Previs√µes com Pipeline Treinado")

# Previs√µes no conjunto de treino
y_train_pred = pipe.predict(X_train)
st.write("üìã Previs√µes no treino (primeiras 10):")
st.write(y_train_pred[:10])

# Previs√µes no conjunto de teste
y_test_pred = pipe.predict(X_test)
st.write("üìã Previs√µes no teste (primeiras 10):")
st.write(y_test_pred[:10])

# Exibe as etapas do pipeline
st.subheader("üîß Etapas do Pipeline")
st.write("üì¶ named_steps:")
st.json({nome: str(etapa) for nome, etapa in pipe.named_steps.items()})

st.write("üì¶ steps (tuplas):")
st.write(pipe.steps)


st.subheader("üîç Componentes principais (PCA) extra√≠dos do pipeline")

try:
    X_train_pca = pipe.named_steps['pca'].transform(X_train)
    st.write("‚úÖ X_train_pca (primeiras linhas):")
    st.dataframe(pd.DataFrame(X_train_pca).head())
except Exception as e:
    st.error(f"Erro ao aplicar PCA extra√≠do do pipeline: {e}")


st.subheader("üß± Codifica√ß√£o de vari√°veis categ√≥ricas (dummies)")

if 'df' in locals():
    dummy = pd.get_dummies(df,
        columns=['sexo', 'posse_de_veiculo', 'posse_de_imovel',
                 'tipo_renda', 'educacao', 'estado_civil', 'tipo_residencia'])
    st.write("‚úÖ DataFrame com vari√°veis dummies:")
    st.dataframe(dummy.head())
else:
    st.warning("‚ö†Ô∏è DataFrame 'df' n√£o foi carregado.")


import streamlit as st
import pandas as pd

# Carrega o dataframe original
# 

# Apenas para exemplo, vamos criar um DataFrame dummy se n√£o tiver um ainda
# df = pd.DataFrame({...})

st.title("Pr√©-processamento de Dados para Modelagem")

# Exibe os tipos de dados do dummy (se existir)
if 'dummy' in locals():
    st.subheader("Tipos de dados (dummy):")
    st.write(dummy.dtypes)

# Amostragem inicial
dataset = df.sample(40000, random_state=42)

st.subheader("Colunas do DataFrame:")
st.write(df.columns.tolist())

# Remove colunas desnecess√°rias
cols_to_drop = ['data_ref', 'index']
dataset.drop(cols_to_drop, axis=1, inplace=True, errors='ignore')  # evita erro se a coluna n√£o existir

# Divide o dataset
data = dataset.sample(frac=0.95, random_state=786)
data_unseen = dataset.drop(data.index)

# Reseta √≠ndices
data.reset_index(inplace=True, drop=True)
data_unseen.reset_index(inplace=True, drop=True)

# Exibe os tamanhos dos conjuntos
st.subheader("Tamanhos dos conjuntos de dados:")
st.write(f"Conjunto para modelagem (treino/teste): {data.shape}")
st.write(f"Conjunto n√£o visto (valida√ß√£o): {data_unseen.shape}")


########################

from pycaret.classification import *

from pycaret.classification import ClassificationExperiment

exp = ClassificationExperiment()

exp.setup(
    data=data,
    target='mau',
    experiment_name='credit_1',
    normalize=True,
    normalize_method='zscore',
    transformation=True,
    transformation_method='quantile',
    fix_imbalance=True
)


best_model = exp.compare_models(fold=4, sort='AUC')
exp.plot_model(best_model, plot='feature')
exp.save_model(best_model, 'LR_Model_Aula5_062022')

###############################

#Modificando os dados de treinamento 

from pycaret.classification import*

# Simula√ß√£o do carregamento dos dados 

st.title("Pr√©-processamento de Dados")

# Exibe os tipos das colunas antes da convers√£o
st.subheader("Tipos de dados antes da convers√£o:")
st.write(data.dtypes)

# Convers√£o da coluna 'qtd_filhos' para float
if 'qtd_filhos' in data.columns:
    try:
        data['qtd_filhos'] = data['qtd_filhos'].astype(float)
        st.success("Coluna 'qtd_filhos' convertida para float com sucesso!")
    except Exception as e:
        st.error(f"Erro ao converter 'qtd_filhos': {e}")
else:
    st.warning("Coluna 'qtd_filhos' n√£o encontrada no DataFrame.")

# Tipos de dados ap√≥s a convers√£o
st.subheader("Tipos de dados ap√≥s a convers√£o:")
st.write(data.dtypes)

########

st.title("An√°lise Explorat√≥ria")

# Supondo que o DataFrame `data` j√° est√° carregado e pr√©-processado

# 1. Correla√ß√£o entre vari√°veis num√©ricas
st.subheader("Matriz de Correla√ß√£o")

numeric_data = data.select_dtypes(include=['number'])
data_corr = numeric_data.corr()
st.dataframe(data_corr)

# Heatmap da correla√ß√£o (opcional)
st.subheader("Heatmap de Correla√ß√£o")

fig, ax = plt.subplots(figsize=(10, 8))
sns.heatmap(data_corr, annot=True, fmt=".2f", cmap="coolwarm", square=True, ax=ax)
st.pyplot(fig)

# 2. Distribui√ß√£o percentual da vari√°vel alvo 'mau'
st.subheader("Distribui√ß√£o da Vari√°vel Alvo ('mau')")

if 'mau' in data.columns:
    target_distribution = data['mau'].value_counts(normalize=True).rename_axis('Classe').reset_index(name='Propor√ß√£o')
    st.dataframe(target_distribution)
    st.bar_chart(target_distribution.set_index('Classe'))
else:
    st.warning("Coluna 'mau' n√£o encontrada no DataFrame.")

########
from pycaret.classification import ClassificationExperiment

st.subheader("Configura√ß√£o do Experimento com PyCaret")

# Cria o experimento
exp = ClassificationExperiment()

# Setup do experimento
with st.spinner("Configurando o experimento..."):
    try:
        exp.setup(
            data=data,
            target='mau',
            experiment_name='credit_1',
            normalize=True,
            normalize_method='zscore',
            transformation=True,
            transformation_method='quantile',
            fix_imbalance=True,
            verbose=False,  # evita prints grandes no terminal
        )
        st.success("Experimento configurado com sucesso!")
    except Exception as e:
        st.error(f"Ocorreu um erro no setup do experimento: {e}")

# Continuando ap√≥s o setup...
st.subheader("Compara√ß√£o de Modelos")

# Bot√£o para comparar modelos
if st.button("Encontrar Melhor Modelo (AUC)"):
    with st.spinner("Comparando modelos... Isso pode levar alguns segundos."):
        try:
            best_model = exp.compare_models(fold=4, sort='AUC')
            st.success(f"Melhor modelo encontrado: {type(best_model).__name__}")
            st.write(best_model)
        except Exception as e:
            st.error(f"Ocorreu um erro ao comparar os modelos: {e}")
else:
    best_model = None

# Plots s√≥ se o melhor modelo j√° foi gerado
if best_model is not None:
    st.subheader("Import√¢ncia das Vari√°veis")
    with st.spinner("Gerando gr√°fico de import√¢ncia..."):
        exp.plot_model(best_model, plot='feature', display_format='streamlit')

    st.subheader("Curva ROC / AUC")
    with st.spinner("Gerando curva AUC..."):
        exp.plot_model(best_model, plot='auc', display_format='streamlit')


# Salvando o modelo

from pycaret.classification import save_model, load_model
import os

st.subheader("Salvar e Carregar Modelo")

# Caminho/nome do modelo
model_name = 'LR_Model_Aula_5_062022'

# Bot√£o para salvar modelo
if best_model is not None:
    if st.button("Salvar Modelo"):
        try:
            save_model(best_model, model_name)
            st.success(f"Modelo salvo com o nome: {model_name}")
        except Exception as e:
            st.error(f"Erro ao salvar modelo: {e}")

# Bot√£o para carregar modelo
if os.path.exists(model_name + '.pkl'):
    if st.button("Carregar Modelo"):
        try:
            model_loaded = load_model(model_name)
            st.success("Modelo carregado com sucesso!")
            st.write("Modelo carregado:", type(model_loaded).__name__)

            # Exibir componentes do pipeline, se aplic√°vel
            if hasattr(model_loaded, 'named_steps'):
                st.subheader("Componentes do Pipeline:")
                st.write(model_loaded.named_steps)
            else:
                st.info("O modelo carregado n√£o √© um pipeline com named_steps.")
        except Exception as e:
            st.error(f"Erro ao carregar modelo: {e}")
else:
    st.warning("Modelo ainda n√£o foi salvo. Clique em 'Salvar Modelo' primeiro.")


st.subheader("Novo Setup com Dataset 'dummy'")

exp2 = ClassificationExperiment()

# Setup com tratamento de multicolinearidade e binning
with st.spinner("Configurando o novo experimento..."):
    try:
        exp2.setup(
            data=dummy,
            target='mau',
            normalize=True,
            transformation=True,
            remove_multicollinearity=True,
            multicollinearity_threshold=0.95,
            bin_numeric_features=[
                'qtd_filhos', 'idade', 'tempo_emprego', 
                'qt_pessoas_residencia', 'renda'
            ],
            verbose=False
        )
        st.success("Novo experimento configurado com sucesso usando 'dummy'!")
    except Exception as e:
        st.error(f"Ocorreu um erro no novo setup: {e}")


st.subheader("Cria√ß√£o e Avalia√ß√£o do Modelo LightGBM")

# Bot√£o para criar o modelo LightGBM
if st.button("Criar e Avaliar LightGBM"):
    with st.spinner("Criando modelo LightGBM..."):
        try:
            lightgbm = exp2.create_model('lightgbm')
            st.success("Modelo LightGBM criado com sucesso!")
            st.write(lightgbm)

            st.info("Ajustando hiperpar√¢metros...")
            tuned_lightgbm = exp2.tune_model(lightgbm)
            st.success("Modelo LightGBM tunado com sucesso!")
            st.write(tuned_lightgbm)

            final_lightgbm = exp2.finalize_model(tuned_lightgbm)
            st.success("Modelo finalizado e pronto para produ√ß√£o!")

            st.subheader("Avalia√ß√£o do Modelo Final")
            exp2.evaluate_model(final_lightgbm)

        except Exception as e:
            st.error(f"Ocorreu um erro durante o processo com LightGBM: {e}")


st.subheader("Gr√°ficos do Modelo Final - LightGBM")

# Bot√£o para exibir os gr√°ficos
if st.button("Exibir Gr√°ficos (AUC e Confusion Matrix)"):
    with st.spinner("Gerando curva AUC..."):
        try:
            exp2.plot_model(final_lightgbm, plot='auc', display_format='streamlit')
            st.success("Curva AUC exibida com sucesso!")
        except Exception as e:
            st.error(f"Erro ao exibir curva AUC: {e}")

    with st.spinner("Gerando Matriz de Confus√£o..."):
        try:
            exp2.plot_model(final_lightgbm, plot='confusion_matrix', display_format='streamlit')
            st.success("Matriz de Confus√£o exibida com sucesso!")
        except Exception as e:
            st.error(f"Erro ao exibir matriz de confus√£o: {e}")
